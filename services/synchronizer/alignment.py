"""
–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ –º–µ–∂–¥—É –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞–º–∏
"""

import pandas as pd
from typing import Dict
from utils.logger_config import setup_logger
from .constants import ARTICLE_COLUMNS

logger = setup_logger('alignment')


class ArticleAligner:
    """–í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∞—Ä—Ç–∏–∫—É–ª–æ–≤ - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö —Å—Ç—Ä–æ–∫ –≤ DataFrame"""
    
    @staticmethod
    def align_articles(dfs: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:
        """
        –í—ã—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∞—Ä—Ç–∏–∫—É–ª—ã –º–µ–∂–¥—É –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞–º–∏ - –¥–æ–±–∞–≤–ª—è–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç—Ä–æ–∫–∏
        
        Args:
            dfs: —Å–ª–æ–≤–∞—Ä—å —Å DataFrame –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞
            
        Returns:
            –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏
        """
        logger.info("\n" + "="*60)
        logger.info("–í–´–†–ê–í–ù–ò–í–ê–ù–ò–ï –ê–†–¢–ò–ö–£–õ–û–í –ú–ï–ñ–î–£ –ú–ê–†–ö–ï–¢–ü–õ–ï–ô–°–ê–ú–ò")
        logger.info("="*60)
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã –∏–∑ –≤—Å–µ—Ö –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤
        all_articles = ArticleAligner._collect_all_articles(dfs)
        logger.info(f"\nüîç –í—Å–µ–≥–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤: {len(all_articles)}")
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∞—Ä—Ç–∏–∫—É–ª—ã
        total_added = 0
        for marketplace in ['wildberries', 'ozon', 'yandex']:
            article_col = ARTICLE_COLUMNS[marketplace]
            
            if article_col not in dfs[marketplace].columns:
                logger.warning(f"‚ö†Ô∏è {marketplace.upper()}: —Å—Ç–æ–ª–±–µ—Ü '{article_col}' –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞—é")
                continue
            
            added = ArticleAligner._add_missing_articles(
                dfs[marketplace], 
                marketplace, 
                article_col, 
                all_articles
            )
            
            if added > 0:
                dfs[marketplace] = dfs[marketplace]
                total_added += added
                logger.info(f" üìä {marketplace.upper()}: –¥–æ–±–∞–≤–ª–µ–Ω–æ {added} –∞—Ä—Ç–∏–∫—É–ª–æ–≤")
        
        if total_added > 0:
            logger.info(f"\n‚úÖ –ò—Ç–æ–≥–æ –¥–æ–±–∞–≤–ª–µ–Ω–æ {total_added} –Ω–æ–≤—ã—Ö —Å—Ç—Ä–æ–∫ –≤–æ –≤—Å–µ –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å—ã")
        else:
            logger.info(f"\n‚úÖ –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è - –≤—Å–µ –∞—Ä—Ç–∏–∫—É–ª—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
        
        return dfs
    
    @staticmethod
    def _collect_all_articles(dfs: Dict[str, pd.DataFrame]) -> set:
        """–°–æ–±–∏—Ä–∞–µ—Ç –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª—ã –∏–∑ –≤—Å–µ—Ö –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–æ–≤"""
        all_articles = set()
        
        for marketplace in ['wildberries', 'ozon', 'yandex']:
            article_col = ARTICLE_COLUMNS[marketplace]
            
            if article_col in dfs[marketplace].columns:
                articles = dfs[marketplace][article_col].dropna().astype(str).str.strip()
                articles = articles[articles != '']  # –£–±–∏—Ä–∞–µ–º –ø—É—Å—Ç—ã–µ
                
                # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è: –£–±–∏—Ä–∞–µ–º –æ–ø–∏—Å–∞–Ω–∏—è –ø–æ–ª–µ–π –∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                articles = articles[
                    ~articles.str.contains(
                        '–∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å|–æ–ø–∏—Å–∞–Ω–∏–µ|–∑–∞–ø–æ–ª–Ω–∏—Ç—å|–ø—Ä–∏–º–µ—Ä|–Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞|–ø–æ –∫–æ—Ç–æ—Ä–æ–º—É',
                        case=False,
                        na=False
                    )
                ]
                
                # –£–±–∏—Ä–∞–µ–º —Å—Ç—Ä–æ–∫–∏ –¥–ª–∏–Ω–Ω–µ–µ 50 —Å–∏–º–≤–æ–ª–æ–≤ (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –æ–ø–∏—Å–∞–Ω–∏–µ)
                articles = articles[articles.str.len() < 50]
                
                all_articles.update(articles.tolist())
                logger.info(f"üìä {marketplace.upper()}: {len(articles)} –∞—Ä—Ç–∏–∫—É–ª–æ–≤")
        
        return all_articles
    
    @staticmethod
    def _add_missing_articles(
        df: pd.DataFrame, 
        marketplace: str, 
        article_col: str, 
        all_articles: set
    ) -> int:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ –∞—Ä—Ç–∏–∫—É–ª—ã –≤ DataFrame"""
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –ü–ï–†–ï–î –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
        df_reset = df.reset_index(drop=True)
        
        # –ù–∞—Ö–æ–¥–∏–º —Å—Ç—Ä–æ–∫–∏ —Å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–º–∏ –∞—Ä—Ç–∏–∫—É–ª–∞–º–∏
        article_series = df_reset[article_col].dropna().astype(str).str.strip()
        article_series = article_series[article_series != '']
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
        valid_mask = (
            ~article_series.str.contains(
                '–∏–¥–µ–Ω—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å|–æ–ø–∏—Å–∞–Ω–∏–µ|–∑–∞–ø–æ–ª–Ω–∏—Ç—å|–ø—Ä–∏–º–µ—Ä|–Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞|–ø–æ –∫–æ—Ç–æ—Ä–æ–º—É',
                case=False,
                na=False
            ) &
            (article_series.str.len() < 50)
        )
        
        article_series = article_series[valid_mask]
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
        if len(article_series) > 0:
            last_label_idx = article_series.index[-1]
            last_filled_position = df_reset.index.get_loc(last_label_idx)
        else:
            last_filled_position = -1
        
        existing_articles_set = set(article_series.tolist())
        
        # –ù–∞—Ö–æ–¥–∏–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ
        missing_articles = all_articles - existing_articles_set
        
        if not missing_articles:
            logger.info(f"‚úÖ {marketplace.upper()}: –≤—Å–µ –∞—Ä—Ç–∏–∫—É–ª—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç")
            return 0
        
        logger.info(f"\n‚ûï {marketplace.upper()}: –¥–æ–±–∞–≤–ª—è—é {len(missing_articles)} –∞—Ä—Ç–∏–∫—É–ª–æ–≤")
        
        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –∞—Ä—Ç–∏–∫—É–ª–æ–≤
        new_rows = []
        for article in sorted(missing_articles):
            # –°–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É —Å–æ –≤—Å–µ–º–∏ —Å—Ç–æ–ª–±—Ü–∞–º–∏
            new_row = {col: None for col in df_reset.columns}
            # –ó–∞–ø–æ–ª–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –∞—Ä—Ç–∏–∫—É–ª
            new_row[article_col] = article
            new_rows.append(new_row)
        
        # –í—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ –°–†–ê–ó–£ –ü–û–°–õ–ï –ø–æ—Å–ª–µ–¥–Ω–µ–π –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω–æ–π
        if new_rows:
            new_df = pd.DataFrame(new_rows)
            
            if last_filled_position >= 0:
                # –ï—Å—Ç—å –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ - –≤—Å—Ç–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ –Ω–∏—Ö
                before = df_reset.iloc[:last_filled_position + 1].copy()
                after = df_reset.iloc[last_filled_position + 1:].copy()
                
                # –°–∫–ª–µ–∏–≤–∞–µ–º: –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ + –Ω–æ–≤—ã–µ + –ø—É—Å—Ç—ã–µ
                result_df = pd.concat([before, new_df, after], ignore_index=True)
                logger.info(f" ‚úì –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_rows)} —Å—Ç—Ä–æ–∫ –ø–æ—Å–ª–µ –ø–æ–∑–∏—Ü–∏–∏ {last_filled_position}")
            else:
                # –ù–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ - –¥–æ–±–∞–≤–ª—è–µ–º –≤ –Ω–∞—á–∞–ª–æ
                result_df = pd.concat([new_df, df_reset], ignore_index=True)
                logger.info(f" ‚úì –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_rows)} —Å—Ç—Ä–æ–∫ –≤ –Ω–∞—á–∞–ª–æ")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π DataFrame
            df.drop(df.index, inplace=True)
            for col in result_df.columns:
                df[col] = result_df[col].values
            
            logger.info(f" üìä –ë—ã–ª–æ: {len(df_reset)}, —Å—Ç–∞–ª–æ: {len(result_df)}")
            return len(new_rows)
        
        return 0
